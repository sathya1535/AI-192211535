import numpy as np

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return x * (1 - x)

class SimpleNN:
    def __init__(self):
        self.weights = np.random.rand(2, 1)

    def forward(self, inputs):
        return sigmoid(np.dot(inputs, self.weights))

    def train(self, inputs, targets, learning_rate, epochs):
        for _ in range(epochs):
            output = self.forward(inputs)
            error = targets - output
            adjustments = np.dot(inputs.T, error * sigmoid_derivative(output))
            self.weights += adjustments * learning_rate

inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
targets = np.array([[0], [1], [1], [0]])

nn = SimpleNN()
nn.train(inputs, targets, learning_rate=0.1, epochs=10000)
print(nn.forward(inputs))
